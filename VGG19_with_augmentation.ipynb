{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omarjilanijidan/Iris-Cataract-Detection-From-Fundus-Images/blob/main/VGG19_with_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cbgwZWWfWpp"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Msgd9t7rod69"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PscwOt5QojIJ",
        "outputId": "c57b4915-1ed0-4117-e6b8-e3b27d4c178f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Authenticate and mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JbazpqzojZF"
      },
      "outputs": [],
      "source": [
        "image_size = 224\n",
        "dataset_dir = \"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcwtt-uDovWL"
      },
      "outputs": [],
      "source": [
        "def create_dataset(image_category, label):\n",
        "    dataset = []\n",
        "    labels = []\n",
        "    image_folder = os.path.join(dataset_dir, image_category)\n",
        "    for img in tqdm(os.listdir(image_folder)[:1000]):\n",
        "        image_path = os.path.join(image_folder, img)\n",
        "        try:\n",
        "            image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "            if image is None:\n",
        "                raise Exception(\"Failed to load image data\")\n",
        "            image = cv2.resize(image, (image_size, image_size))\n",
        "            image = image / 255.0\n",
        "            dataset.append(image)\n",
        "            labels.append(label)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "    return np.array(dataset), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdxX6f58oya-",
        "outputId": "d7c959ac-9543-4df2-a7d4-83eeb7c30b4a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:11<00:00, 88.53it/s]\n",
            "100%|██████████| 1000/1000 [00:08<00:00, 114.32it/s]\n"
          ]
        }
      ],
      "source": [
        "cataract_images, cataract_labels = create_dataset(\"/content/drive/MyDrive/Papers/Dataset Fundus Image/Cataract\", 1)\n",
        "normal_images, normal_labels = create_dataset(\"/content/drive/MyDrive/Papers/Dataset Fundus Image/NDG\", 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCGiaMI0o1Of"
      },
      "outputs": [],
      "source": [
        "X = np.concatenate((cataract_images, normal_images[:1000]), axis=0)\n",
        "y = np.concatenate((cataract_labels, normal_labels[:1000]), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9GZzUfno3sq"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ng6jAdJHplxe",
        "outputId": "dc5446b0-22e1-487f-a42e-bf86cea2910a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of images used for training: 1600\n",
            "Number of images used for testing: 400\n"
          ]
        }
      ],
      "source": [
        "# Print number of images used for training and testing\n",
        "print(f\"Number of images used for training: {len(X_train)}\")\n",
        "print(f\"Number of images used for testing: {len(X_test)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zBcLhd1o56E"
      },
      "outputs": [],
      "source": [
        "# Pre-augmentation\n",
        "augmented_images = []\n",
        "augmented_labels = []\n",
        "#Augmentation training data\n",
        "for image, label in zip(X_train, y_train):\n",
        "    # Random rotation\n",
        "    random_rotation = random.uniform(-20, 20)\n",
        "    rotated_image = cv2.getRotationMatrix2D((image_size / 2, image_size / 2), random_rotation, 1)\n",
        "    rotated_image = cv2.warpAffine(image, rotated_image, (image_size, image_size))\n",
        "    augmented_images.append(rotated_image)\n",
        "    augmented_labels.append(label)\n",
        "\n",
        "    # Random horizontal flip\n",
        "    if random.random() > 0.5:\n",
        "        flipped_image = cv2.flip(image, 1)\n",
        "        augmented_images.append(flipped_image)\n",
        "        augmented_labels.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8tQ7fTvo8gY"
      },
      "outputs": [],
      "source": [
        "# Concatenate augmented images and labels with original data\n",
        "X_train = np.concatenate((X_train, np.array(augmented_images)), axis=0)\n",
        "y_train = np.concatenate((y_train, np.array(augmented_labels)), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM0AsFg8pYIz",
        "outputId": "4ff16285-49f0-482e-d6f3-958072580970"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of images used for training: 3997\n",
            "Number of images used for testing: 400\n"
          ]
        }
      ],
      "source": [
        "# Print number of images used for training and testing\n",
        "print(f\"Number of images used for training: {len(X_train)}\")\n",
        "print(f\"Number of images used for testing: {len(X_test)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_jz5ujet5dt",
        "outputId": "1dd8066c-ebb9-4a96-97e6-ef7fa6aa1b30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Create VGG19 base model\n",
        "vgg19 = VGG19(include_top=False, weights=\"imagenet\", input_shape=(image_size, image_size, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4U6D2PQt9Df"
      },
      "outputs": [],
      "source": [
        "# Freeze base model layers\n",
        "for layer in vgg19.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmJQcbxjuA-V"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "# Create custom model with VGG19 base and fully connected layers\n",
        "inputs = vgg19.input\n",
        "outputs = vgg19.output\n",
        "outputs = Dropout(0.5)(outputs)\n",
        "outputs = Dense(512, activation=\"relu\")(outputs)\n",
        "outputs = Dropout(0.5)(outputs)\n",
        "outputs = Dense(49, activation=\"sigmoid\")(outputs)\n",
        "outputs = GlobalAveragePooling2D()(outputs)\n",
        "predictions = Dense(1, activation=\"sigmoid\")(outputs)\n",
        "model = Model(inputs=inputs, outputs=predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbRxRnHcuDgs"
      },
      "outputs": [],
      "source": [
        "# Compile model\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_iC9tRruF4B",
        "outputId": "95b791e7-c3b7-4e59-b0ca-0db91886b054"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "82/82 [==============================] - 1401s 17s/step - loss: 0.3411 - accuracy: 0.8899 - val_loss: 0.1805 - val_accuracy: 0.9425\n",
            "Epoch 2/10\n",
            "82/82 [==============================] - 1398s 17s/step - loss: 0.1811 - accuracy: 0.9437 - val_loss: 0.1434 - val_accuracy: 0.9425\n",
            "Epoch 3/10\n",
            "82/82 [==============================] - 1399s 17s/step - loss: 0.1493 - accuracy: 0.9515 - val_loss: 0.1250 - val_accuracy: 0.9700\n",
            "Epoch 4/10\n",
            "82/82 [==============================] - 1393s 17s/step - loss: 0.1412 - accuracy: 0.9490 - val_loss: 0.1191 - val_accuracy: 0.9700\n",
            "Epoch 5/10\n",
            "82/82 [==============================] - 1390s 17s/step - loss: 0.1318 - accuracy: 0.9532 - val_loss: 0.1161 - val_accuracy: 0.9525\n",
            "Epoch 6/10\n",
            "82/82 [==============================] - 1392s 17s/step - loss: 0.1223 - accuracy: 0.9560 - val_loss: 0.1139 - val_accuracy: 0.9575\n",
            "Epoch 7/10\n",
            "82/82 [==============================] - 1392s 17s/step - loss: 0.1243 - accuracy: 0.9527 - val_loss: 0.1087 - val_accuracy: 0.9675\n",
            "Epoch 8/10\n",
            "67/82 [=======================>......] - ETA: 3:51 - loss: 0.1206 - accuracy: 0.9561"
          ]
        }
      ],
      "source": [
        "# Fit model on train data\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=49, validation_data=(X_test, y_test))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}