# -*- coding: utf-8 -*-
"""Copy of Cataract_Detection_using_VGG19.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WMeyTnM_Muz09WRyk10sUVOEZvJglY3F
"""

# Import necessary libraries
import os
import numpy as np
import cv2
import random
from tqdm import tqdm
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.vgg19 import VGG19
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.models import Model

# Authenticate and mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Set image size
image_size = 224

dataset_dir = "/kaggle/input/fundus-images-for-cataract-classification"

def create_dataset(image_category, label):
    dataset = []
    labels = []
    image_folder = os.path.join(dataset_dir, image_category)
    # Only select the images
    for img in tqdm(os.listdir(image_folder)[:1000]):
        image_path = os.path.join(image_folder, img)
        try:
            image = cv2.imread(image_path, cv2.IMREAD_COLOR)
            if image is None:
                raise Exception("Failed to load image data")
            
            # Resize and normalize image
            image = cv2.resize(image, (image_size, image_size))
            image = image / 255.0

            # Add image and label to dataset
            dataset.append(image)
            labels.append(label)
        except Exception as e:
            print(e)
    return np.array(dataset), np.array(labels)

# Load cataract and non-cataract datasets
cataract_images, cataract_labels = create_dataset("/content/drive/MyDrive/Papers/Dataset Fundus Image/Cataract", 1)
normal_images, normal_labels = create_dataset("/content/drive/MyDrive/Papers/Dataset Fundus Image/NDG", 0)

# Concatenate datasets and labels
X = np.concatenate((cataract_images, normal_images[:1000]), axis=0)
y = np.concatenate((cataract_labels, normal_labels[:1000]), axis=0)

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create image generator for data augmentation
datagen = ImageDataGenerator(rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, 
                             horizontal_flip=True,vertical_flip= True,zoom_range = 0.2, fill_mode='nearest')

# Print number of images used for training and testing
print(f"Number of images used for training: {len(X_train)}")
print(f"Number of images used for testing: {len(X_test)}")

# Create VGG19 base model
vgg19 = VGG19(include_top=False, weights="imagenet", input_shape=(image_size, image_size, 3))

# Freeze base model layers
for layer in vgg19.layers:
    layer.trainable = False

from tensorflow.keras.layers import GlobalAveragePooling2D
# Create custom model with VGG19 base and fully connected layers
inputs = vgg19.input
outputs = vgg19.output
outputs = Dropout(0.5)(outputs)
outputs = Dense(512, activation="relu")(outputs)
outputs = Dropout(0.5)(outputs)
outputs = Dense(49, activation="sigmoid")(outputs)
outputs = GlobalAveragePooling2D()(outputs)
predictions = Dense(1, activation="sigmoid")(outputs)
model = Model(inputs=inputs, outputs=predictions)

# Compile model
model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])

# Fit model on train data
history = model.fit(datagen.flow(X_train, y_train, batch_size=49), epochs=15, validation_data=(X_test, y_test))