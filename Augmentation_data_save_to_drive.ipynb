{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omarjilanijidan/Iris-Cataract-Detection-From-Fundus-Images/blob/main/Augmentation_data_save_to_drive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cbgwZWWfWpp"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAb77yZ9fzMG"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pafL7Li0jyXW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7efc5900-dde4-4391-b0cb-ddb033b271f1"
      },
      "source": [
        "# Authenticate and mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 224\n",
        "dataset_dir = \"\""
      ],
      "metadata": {
        "id": "7LEvd47uy6nU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(image_category, label):\n",
        "    dataset = []\n",
        "    labels = []\n",
        "    image_folder = os.path.join(dataset_dir, image_category)\n",
        "    for img in tqdm(os.listdir(image_folder)[:1000]):\n",
        "        image_path = os.path.join(image_folder, img)\n",
        "        try:\n",
        "            image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "            if image is None:\n",
        "                raise Exception(\"Failed to load image data\")\n",
        "            image = cv2.resize(image, (image_size, image_size))\n",
        "            image = image / 255.0\n",
        "            dataset.append(image)\n",
        "            labels.append(label)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "    return np.array(dataset), np.array(labels)"
      ],
      "metadata": {
        "id": "cG_Bq95hy8nS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cataract_images, cataract_labels = create_dataset(\"/content/drive/MyDrive/Papers/Dataset Fundus Image/Cataract\", 1)\n",
        "normal_images, normal_labels = create_dataset(\"/content/drive/MyDrive/Papers/Dataset Fundus Image/NDG\", 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCeiQSuGy-dt",
        "outputId": "18ea023d-1ff6-41a7-b40a-817569dbce5c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:42<00:00, 23.54it/s]\n",
            "100%|██████████| 1000/1000 [01:32<00:00, 10.75it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.concatenate((cataract_images, normal_images[:1000]), axis=0)\n",
        "y = np.concatenate((cataract_labels, normal_labels[:1000]), axis=0)"
      ],
      "metadata": {
        "id": "s0zm-yRCzGE4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ezTVG6iHzIbX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print number of images used for training and testing\n",
        "print(f\"Number of images used for training: {len(X_train)}\")\n",
        "print(f\"Number of images used for testing: {len(X_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgp5Yg5XzK7_",
        "outputId": "e8b754ae-bc94-417c-934e-a4637c71c0c8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images used for training: 1600\n",
            "Number of images used for testing: 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-augmentation\n",
        "augmented_train_images = []\n",
        "augmented_train_labels = []\n",
        "augmented_test_images = []\n",
        "augmented_test_labels = []\n",
        "\n",
        "# Augmentation for training data\n",
        "for image, label in zip(X_train, y_train):\n",
        "    # Random rotation\n",
        "    random_rotation = random.uniform(-20, 20)\n",
        "    rotated_image = cv2.getRotationMatrix2D((image_size / 2, image_size / 2), random_rotation, 1)\n",
        "    rotated_image = cv2.warpAffine(image, rotated_image, (image_size, image_size))\n",
        "    augmented_train_images.append(rotated_image)\n",
        "    augmented_train_labels.append(label)\n",
        "\n",
        "    # Random horizontal flip\n",
        "    if random.random() > 0.5:\n",
        "        flipped_image = cv2.flip(image, 1)\n",
        "        augmented_train_images.append(flipped_image)\n",
        "        augmented_train_labels.append(label)\n",
        "\n",
        "# Augmentation for testing data\n",
        "for image, label in zip(X_test, y_test):\n",
        "    # Random rotation\n",
        "    random_rotation = random.uniform(-20, 20)\n",
        "    rotated_image = cv2.getRotationMatrix2D((image_size / 2, image_size / 2), random_rotation, 1)\n",
        "    rotated_image = cv2.warpAffine(image, rotated_image, (image_size, image_size))\n",
        "    augmented_test_images.append(rotated_image)\n",
        "    augmented_test_labels.append(label)\n",
        "\n",
        "    # Random horizontal flip\n",
        "    if random.random() > 0.5:\n",
        "        flipped_image = cv2.flip(image, 1)\n",
        "        augmented_test_images.append(flipped_image)\n",
        "        augmented_test_labels.append(label)"
      ],
      "metadata": {
        "id": "S-vX1sZwzOSf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate augmented images and labels with original data for training set\n",
        "X_train = np.concatenate((X_train, np.array(augmented_train_images)), axis=0)\n",
        "y_train = np.concatenate((y_train, np.array(augmented_train_labels)), axis=0)\n",
        "\n",
        "# Concatenate augmented images and labels with original data for testing set\n",
        "X_test = np.concatenate((X_test, np.array(augmented_test_images)), axis=0)\n",
        "y_test = np.concatenate((y_test, np.array(augmented_test_labels)), axis=0)"
      ],
      "metadata": {
        "id": "Yst0nk8qzQto"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define file paths for saving data\n",
        "save_path = '/content/drive/MyDrive/Papers/Dataset Fundus Image/augmented-data'\n",
        "train_images_path = os.path.join(save_path, 'X_train.npy')\n",
        "train_labels_path = os.path.join(save_path, 'y_train.npy')\n",
        "test_images_path = os.path.join(save_path, 'X_test.npy')\n",
        "test_labels_path = os.path.join(save_path, 'y_test.npy')\n",
        "\n",
        "\n",
        "\n",
        "# Save training and testing data to Google Drive\n",
        "np.save(train_images_path, X_train)\n",
        "np.save(train_labels_path, y_train)\n",
        "np.save(test_images_path, X_test)\n",
        "np.save(test_labels_path, y_test)"
      ],
      "metadata": {
        "id": "Q0JPqdY3_tx0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print number of images used for training and testing\n",
        "print(f\"Number of images used for training: {len(X_train)}\")\n",
        "print(f\"Number of images used for testing: {len(X_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50DLKG2vzSpB",
        "outputId": "77861ab5-b738-4ed9-abd7-e4a2d49d6346"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images used for training: 3997\n",
            "Number of images used for testing: 1004\n"
          ]
        }
      ]
    }
  ]
}